{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ba7049d-e0f8-41af-b706-f1345974ad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, accuracy_score\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43960c27-53b0-4b27-9ee4-1e3d07de285d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load raw data from csv\n",
    "loaners = pd.read_csv('Task_3_and_4_Loan_Data.csv')\n",
    "df = loaners.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775f3ebc-67fe-4fa8-b0ab-e9f8b513c315",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fc74b83-5b22-4bc1-a349-260468bdb53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5eb53670-c2e9-4041-9654-0ed38331cfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6b8b57-6dd8-4d5b-a416-d69a8aa29339",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d949c93-14a5-4f63-bb32-325f579fc5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['customer_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b418cb-a5ed-4d9d-8117-628e7812cdf3",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e03f7bd0-6393-411a-adbe-c72fa6539bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratios\n",
    "df['loan_to_debt'] = df['loan_amt_outstanding'] / df['total_debt_outstanding']\n",
    "df['loan_to_income'] = df['loan_amt_outstanding'] / df['income']\n",
    "df['debt_to_income'] = df['total_debt_outstanding'] / df['income']\n",
    "# Interaction terms\n",
    "df['loan_empyears_interac'] = df['loan_amt_outstanding'] * df['years_employed']\n",
    "df['debt_empyears_interac'] = df['total_debt_outstanding'] * df['years_employed']\n",
    "df['income_fico_interac'] = df['income'] * df['fico_score']\n",
    "df['crlines_fico_interac'] = df['credit_lines_outstanding'] * df['fico_score']\n",
    "df['crlines_income_interac'] = df['credit_lines_outstanding'] * df['income']\n",
    "df['crlines_empyears_interac'] = df['credit_lines_outstanding'] * df['years_employed']\n",
    "df['empyears_fico_interac'] = df['years_employed'] * df['fico_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd75691-00d1-4098-a832-e50e1baec2dc",
   "metadata": {},
   "source": [
    "#### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df20d019-d5d4-4780-93c8-f3515505012a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature skewness\n",
    "skewness = df.skew()\n",
    "print(skewness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c15b286f-e2e1-48ab-8eae-84942acb6ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply log transformation on positively skewed features\n",
    "df['credit_lines_outstanding'] = np.log1p(df['credit_lines_outstanding'])\n",
    "df['total_debt_outstanding'] = np.log1p(df['total_debt_outstanding'])\n",
    "df['loan_to_debt'] = np.log1p(df['loan_to_debt'])\n",
    "df['debt_empyears_interac'] = np.log1p(df['debt_empyears_interac'])\n",
    "df['crlines_fico_interac'] = np.log1p(df['crlines_fico_interac'])\n",
    "df['crlines_income_interac'] = np.log1p(df['crlines_income_interac'])\n",
    "df['crlines_empyears_interac'] = np.log1p(df['crlines_empyears_interac'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834d2e69-b138-4fab-b0cf-d1d8d3d756a2",
   "metadata": {},
   "source": [
    "#### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af3c596f-4f3a-41d4-ab1f-d86300fe691b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate target and features\n",
    "features = df.drop(columns=['default'])\n",
    "target = df['default']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "features_scaled_df = pd.DataFrame(features_scaled, columns=features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55ac9ba5-5876-4a36-b9e1-4af1b428896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_scaled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8e43c6-7bd5-4ac6-89a5-516e32111c18",
   "metadata": {},
   "source": [
    "#### Feature Analysis & Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d3a68a3-ebfb-456e-b2b6-0fc89bc92b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the correlation matrix\n",
    "corr_matrix = features_scaled_df.corr()\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c99a825-8517-443e-811e-8b4038e947e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define threshold for feature selection\n",
    "threshold = 0.85\n",
    "\n",
    "# Extract highly correlated pairs\n",
    "features_used = set()\n",
    "features_removed = set()\n",
    "\n",
    "for i in range(corr_matrix.shape[0]):\n",
    "    for j in range(i+1, corr_matrix.shape[1]):\n",
    "        if corr_matrix.iloc[i, j] >= threshold or corr_matrix.iloc[i, j] <= -threshold:\n",
    "            left_feature = corr_matrix.index[i]\n",
    "            right_feature = corr_matrix.columns[j]\n",
    "\n",
    "            if right_feature not in features_used:\n",
    "                features_used.add(right_feature)\n",
    "                features_removed.add(left_feature)\n",
    "\n",
    "# Convert sets to lists for print\n",
    "features_used = list(features_used)\n",
    "features_removed = list(features_removed)\n",
    "\n",
    "print('Features to be used:', features_used)\n",
    "print('Features removed:', features_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d219b81-ffa6-41da-91f0-8069ab791fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled_df, target, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a Random Forest model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Extract feature importance\n",
    "importances = model.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({'Feature': features_scaled_df.columns, \n",
    "                                      'Importance': importances})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c11a242-5128-4cf5-a0ba-b3c5ef3e97e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features with high importance\n",
    "main_features = ['debt_to_income', 'loan_to_debt', 'crlines_income_interac', \n",
    "                 'empyears_fico_interac', 'fico_score']\n",
    "\n",
    "# Calculate VIF for each feature\n",
    "X = features_scaled_df[main_features]\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['Feature'] = X.columns\n",
    "vif_data['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f83358b-502e-4cf2-86de-763bfc0d0670",
   "metadata": {},
   "source": [
    "#### Balancing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03906db8-8e45-44a1-b794-af4e79a7096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE to balance train set\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Retrain the random forest \n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('ROC AUC score:', roc_auc_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "30a4878f-0e37-4c3a-89a9-2ad3a04be272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    random_state=42, \n",
    "    use_label_encoder=False, \n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "# Fit the model on the balanced training data\n",
    "xgb_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"ROC AUC score:\", roc_auc_score(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Predict probabilities for calculating the probability of default\n",
    "xgb_pd = xgb_model.predict_proba(X_test)[:, 1]  # Probabilities of the positive class\n",
    "\n",
    "# Integrate cross-validation to test robustness\n",
    "cross_val_scores = cross_val_score(xgb_model, X_train_balanced, y_train_balanced, cv=5, scoring='roc_auc')\n",
    "print(\"Cross-Validation AUC scores:\", cross_val_scores)\n",
    "print(\"Mean AUC score:\", cross_val_scores.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29f6517e-d3fe-4ac9-b525-1d139fc44e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to plot learning curves\n",
    "def plot_learning_curves(estimator, X, y, scoring='accuracy'):\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=5, scoring=scoring, n_jobs=1, \n",
    "        train_sizes=np.linspace(0.1, 1, 10), random_state=42)\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.title('Learning Curve')\n",
    "    plt.xlabel('Training examples')\n",
    "    plt.ylabel(scoring.capitalize())\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, \n",
    "                     train_scores_mean + train_scores_std, alpha=0.1, color='r')\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, \n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color='g')\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color='r', \n",
    "             label='Training score')\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color='g', \n",
    "             label='Cross-validation score')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "\n",
    "# PLot learning curves for XGBoost\n",
    "plot_learning_curves(xgb_model, X_train_balanced, y_train_balanced, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acef7494-596d-4b53-b166-de5f109283da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
